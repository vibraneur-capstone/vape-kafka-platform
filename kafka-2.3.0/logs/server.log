[2019-10-02 21:46:38,548] INFO Reading configuration from: ../resources/vapeZooKeeperConfig/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-10-02 21:46:38,549] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-10-02 21:46:38,549] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-10-02 21:46:38,549] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-10-02 21:46:38,550] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-10-02 21:46:38,560] INFO Reading configuration from: ../resources/vapeZooKeeperConfig/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-10-02 21:46:38,560] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-10-02 21:46:38,565] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,566] INFO Server environment:host.name=192.168.7.46 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,566] INFO Server environment:java.version=12.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,566] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,566] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,566] INFO Server environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,567] INFO Server environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,567] INFO Server environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,567] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,567] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,567] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,568] INFO Server environment:os.version=10.14.6 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,568] INFO Server environment:user.name=benxinniu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,568] INFO Server environment:user.home=/Users/benxinniu (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,568] INFO Server environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,572] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,572] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,572] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:38,580] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-10-02 21:46:38,588] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:46:51,912] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:46:52,488] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:46:52,488] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:46:52,489] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:46:52,501] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:52,505] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,505] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,506] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,507] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,507] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,507] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,507] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:52,519] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:52,524] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:52,536] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:52,536] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49556 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:46:52,544] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49556 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:52,546] INFO Creating new log file: log.44 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-10-02 21:46:52,565] INFO Established session 0x100178a638b0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49556 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:52,567] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:52,570] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:52,616] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x1 zxid:0x45 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,638] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x2 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,646] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x3 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,655] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x4 zxid:0x48 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,663] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x5 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,670] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x6 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,678] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x7 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,687] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x8 zxid:0x4c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,694] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0x9 zxid:0x4d txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,701] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0xa zxid:0x4e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,708] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0xb zxid:0x4f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,717] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:46:52,717] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0xc zxid:0x50 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,725] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0000 type:create cxid:0xd zxid:0x51 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:52,898] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:46:52,902] WARN No meta.properties file under dir /vape/logs/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:46:52,968] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /vape/logs/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:46:52,977] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /vape/logs/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:46:53,005] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:53,006] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:53,009] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:53,035] INFO Log directory /vape/logs/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-10-02 21:46:53,036] ERROR Failed to create or validate data directory /vape/logs/kafka-logs (kafka.server.LogDirFailureChannel)
java.io.IOException: Failed to create data directory /vape/logs/kafka-logs
	at kafka.log.LogManager.$anonfun$createAndValidateLogDirs$1(LogManager.scala:158)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.createAndValidateLogDirs(LogManager.scala:149)
	at kafka.log.LogManager.<init>(LogManager.scala:80)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-10-02 21:46:53,040] ERROR Shutdown broker because none of the specified log dirs from /vape/logs/kafka-logs can be created or validated (kafka.log.LogManager)
[2019-10-02 21:46:53,230] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:46:53,231] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:46:53,231] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:46:53,244] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:53,248] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,248] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,248] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,248] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,248] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,248] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,249] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,250] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,260] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:53,262] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:53,271] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49558 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:46:53,272] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:53,275] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49558 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:53,282] INFO Established session 0x100178a638b0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49558 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:53,284] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:53,287] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:53,312] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x1 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,327] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x2 zxid:0x54 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,334] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x3 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,342] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x4 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,350] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x5 zxid:0x57 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,357] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x6 zxid:0x58 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,364] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x7 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,372] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x8 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,379] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0x9 zxid:0x5b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,386] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0xa zxid:0x5c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,393] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0xb zxid:0x5d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,399] WARN Unable to read additional data from client sessionid 0x100178a638b0000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:46:53,401] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49556 which had sessionid 0x100178a638b0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:46:53,403] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0xc zxid:0x5e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,410] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0001 type:create cxid:0xd zxid:0x5f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:53,469] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:46:53,534] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:46:53,537] WARN No meta.properties file under dir /vape/logs/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:46:53,581] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /vape/logs/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:46:53,590] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /vape/logs/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:46:53,607] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:53,607] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:53,608] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:53,623] INFO Log directory /vape/logs/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-10-02 21:46:53,625] ERROR Failed to create or validate data directory /vape/logs/kafka-logs (kafka.server.LogDirFailureChannel)
java.io.IOException: Failed to create data directory /vape/logs/kafka-logs
	at kafka.log.LogManager.$anonfun$createAndValidateLogDirs$1(LogManager.scala:158)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.createAndValidateLogDirs(LogManager.scala:149)
	at kafka.log.LogManager.<init>(LogManager.scala:80)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-10-02 21:46:53,628] ERROR Shutdown broker because none of the specified log dirs from /vape/logs/kafka-logs can be created or validated (kafka.log.LogManager)
[2019-10-02 21:46:53,909] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:46:53,910] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:46:53,910] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:46:53,923] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:53,926] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,926] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,926] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,926] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,926] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,926] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,927] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,928] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:46:53,939] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:53,940] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:53,949] INFO Accepted socket connection from /127.0.0.1:49560 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:46:53,950] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:53,953] INFO Client attempting to establish new session at /127.0.0.1:49560 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:53,959] INFO Established session 0x100178a638b0002 with negotiated timeout 6000 for client /127.0.0.1:49560 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:46:53,961] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100178a638b0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:46:53,963] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:46:53,988] WARN Unable to read additional data from client sessionid 0x100178a638b0001, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:46:53,989] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49558 which had sessionid 0x100178a638b0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:46:53,994] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x1 zxid:0x61 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,010] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x2 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,018] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x3 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,026] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x4 zxid:0x64 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,034] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x5 zxid:0x65 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,043] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x6 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,050] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x7 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,058] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x8 zxid:0x68 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,065] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0x9 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,072] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0xa zxid:0x6a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,079] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0xb zxid:0x6b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,088] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0xc zxid:0x6c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,095] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0002 type:create cxid:0xd zxid:0x6d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:46:54,216] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:46:54,219] WARN No meta.properties file under dir /vape/logs/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:46:54,259] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /vape/logs/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:46:54,267] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /vape/logs/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:46:54,284] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:54,284] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:54,285] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:46:54,299] INFO Log directory /vape/logs/kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-10-02 21:46:54,301] ERROR Failed to create or validate data directory /vape/logs/kafka-logs (kafka.server.LogDirFailureChannel)
java.io.IOException: Failed to create data directory /vape/logs/kafka-logs
	at kafka.log.LogManager.$anonfun$createAndValidateLogDirs$1(LogManager.scala:158)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.LogManager.createAndValidateLogDirs(LogManager.scala:149)
	at kafka.log.LogManager.<init>(LogManager.scala:80)
	at kafka.log.LogManager$.apply(LogManager.scala:1022)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:242)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-10-02 21:46:54,303] ERROR Shutdown broker because none of the specified log dirs from /vape/logs/kafka-logs can be created or validated (kafka.log.LogManager)
[2019-10-02 21:46:54,681] WARN Unable to read additional data from client sessionid 0x100178a638b0002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:46:54,681] INFO Closed socket connection for client /127.0.0.1:49560 which had sessionid 0x100178a638b0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:47:01,197] INFO Expiring session 0x100178a638b0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:47:01,197] INFO Expiring session 0x100178a638b0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:47:01,197] INFO Expiring session 0x100178a638b0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:47:01,197] INFO Processed session termination for sessionid: 0x100178a638b0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:47:01,197] INFO Processed session termination for sessionid: 0x100178a638b0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:47:01,197] INFO Processed session termination for sessionid: 0x100178a638b0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:34,342] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:49:34,901] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:49:34,912] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:49:34,912] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:49:34,914] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:49:34,930] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:34,934] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,935] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,936] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,937] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:34,950] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:34,951] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:34,962] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49598 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:49:34,963] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:34,966] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49598 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:49:34,979] INFO Established session 0x100178a638b0003 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49598 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:49:34,980] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:34,983] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:35,011] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x1 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,026] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x2 zxid:0x73 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,035] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x3 zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,043] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x4 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,051] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x5 zxid:0x76 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,058] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x6 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,065] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x7 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,072] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x8 zxid:0x79 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,079] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0x9 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,086] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0xa zxid:0x7b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,093] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0xb zxid:0x7c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,100] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0xc zxid:0x7d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,106] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:create cxid:0xd zxid:0x7e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,243] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:49:35,300] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:49:35,309] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:49:35,330] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:49:35,330] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:49:35,332] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:49:35,360] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:49:35,369] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-10-02 21:49:35,386] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:49:35,389] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:49:35,454] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:49:35,454] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:49:35,455] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:49:35,471] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:35,476] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,476] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,476] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,476] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,476] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,476] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,477] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,478] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,492] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:35,495] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:35,505] INFO Accepted socket connection from /127.0.0.1:49599 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:49:35,507] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:35,510] INFO Client attempting to establish new session at /127.0.0.1:49599 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:49:35,517] INFO Established session 0x100178a638b0004 with negotiated timeout 6000 for client /127.0.0.1:49599 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:49:35,518] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100178a638b0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:35,522] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:35,556] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x1 zxid:0x80 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,571] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x2 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,578] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x3 zxid:0x82 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,585] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x4 zxid:0x83 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,593] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x5 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,600] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x6 zxid:0x85 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,608] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x7 zxid:0x86 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,614] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x8 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,621] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0x9 zxid:0x88 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,628] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0xa zxid:0x89 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,634] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0xb zxid:0x8a txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,641] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0xc zxid:0x8b txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,648] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0004 type:create cxid:0xd zxid:0x8c txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,739] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:49:35,775] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-10-02 21:49:35,776] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:49:35,781] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InconsistentBrokerIdException: Configured broker.id 1 doesn't match stored broker.id 0 in meta.properties. If you moved your data, make sure your configured broker.id matches. If you intend to create a new broker, you should remove all data in your data directories (log.dirs).
	at kafka.server.KafkaServer.getBrokerIdAndOfflineDirs(KafkaServer.scala:715)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:214)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-10-02 21:49:35,783] INFO shutting down (kafka.server.KafkaServer)
[2019-10-02 21:49:35,785] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:35,786] INFO Processed session termination for sessionid: 0x100178a638b0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:35,792] INFO Session: 0x100178a638b0004 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:35,793] INFO Closed socket connection for client /127.0.0.1:49599 which had sessionid 0x100178a638b0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:49:35,794] INFO EventThread shut down for session: 0x100178a638b0004 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:35,795] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:35,799] INFO shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:49:35,799] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-10-02 21:49:35,801] INFO shutting down (kafka.server.KafkaServer)
[2019-10-02 21:49:35,809] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-10-02 21:49:35,810] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-10-02 21:49:35,835] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,836] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,838] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,838] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,851] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:49:35,889] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-10-02 21:49:35,909] INFO Stat of the created znode at /brokers/ids/0 is: 142,142,1570067375899,1570067375899,1,0,0,72083477180907523,194,0,142
 (kafka.zk.KafkaZkClient)
[2019-10-02 21:49:35,910] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.7.46,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 142 (kafka.zk.KafkaZkClient)
[2019-10-02 21:49:35,954] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,958] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,959] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:49:35,979] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:49:35,980] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:49:35,984] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-10-02 21:49:35,999] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:49:36,022] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:49:36,023] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:49:36,023] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:49:36,056] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0003 type:multi cxid:0x28 zxid:0x91 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,064] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:49:36,072] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-10-02 21:49:36,078] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:49:36,078] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:49:36,078] INFO Kafka startTimeMs: 1570067376073 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:49:36,079] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-10-02 21:49:36,304] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:49:36,305] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:49:36,305] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:49:36,317] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:36,321] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,321] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,321] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,321] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,321] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,321] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,322] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,323] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,334] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:36,336] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:36,345] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49602 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:49:36,347] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:36,349] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49602 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:49:36,357] INFO Established session 0x100178a638b0005 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49602 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:49:36,358] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b0005, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:36,361] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:36,387] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x1 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,401] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x2 zxid:0x94 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,408] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x3 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,414] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x4 zxid:0x96 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,423] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x5 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,430] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x6 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,436] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x7 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,443] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x8 zxid:0x9a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,449] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0x9 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,456] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0xa zxid:0x9c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,462] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0xb zxid:0x9d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,469] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0xc zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,476] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0005 type:create cxid:0xd zxid:0x9f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,606] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:49:36,610] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InconsistentBrokerIdException: Configured broker.id 2 doesn't match stored broker.id 0 in meta.properties. If you moved your data, make sure your configured broker.id matches. If you intend to create a new broker, you should remove all data in your data directories (log.dirs).
	at kafka.server.KafkaServer.getBrokerIdAndOfflineDirs(KafkaServer.scala:715)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:214)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-10-02 21:49:36,612] INFO shutting down (kafka.server.KafkaServer)
[2019-10-02 21:49:36,613] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:36,614] INFO Processed session termination for sessionid: 0x100178a638b0005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:49:36,621] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49602 which had sessionid 0x100178a638b0005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:49:36,621] INFO Session: 0x100178a638b0005 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:49:36,623] INFO EventThread shut down for session: 0x100178a638b0005 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:49:36,623] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:49:36,627] INFO shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:49:36,627] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-10-02 21:49:36,629] INFO shutting down (kafka.server.KafkaServer)
[2019-10-02 21:51:51,409] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:51:51,410] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:51:51,412] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-10-02 21:51:51,432] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-10-02 21:51:51,438] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:51:51,438] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:51:51,438] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:51:51,439] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:51:51,448] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:51:51,449] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:51:51,451] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:51:51,455] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-10-02 21:51:51,455] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,550] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,550] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,552] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:51:51,553] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 3000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:51:51,554] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-10-02 21:51:51,554] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:51:51,555] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:51:51,555] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:51:51,555] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:51:51,556] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:51:51,556] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,674] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,674] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,674] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,747] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,747] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,749] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:51:51,750] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-10-02 21:51:51,750] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:51:51,751] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:51:51,751] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:51:51,751] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:51:51,752] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:51:51,753] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:51:51,754] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:51:51,754] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,821] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,821] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:51,822] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,026] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,026] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,026] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,197] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,197] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,198] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,352] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,352] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:51:52,357] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-10-02 21:51:52,358] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:51:52,394] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:51:52,400] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:51:52,401] INFO Processed session termination for sessionid: 0x100178a638b0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:52,416] INFO Session: 0x100178a638b0003 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:52,417] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49598 which had sessionid 0x100178a638b0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:51:52,417] INFO EventThread shut down for session: 0x100178a638b0003 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:51:52,420] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:51:52,420] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:52,768] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:52,769] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:52,768] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:53,773] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:53,773] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:53,774] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:54,777] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:54,777] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:54,779] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:51:54,802] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:51:54,804] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:51:58,752] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:51:59,352] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:51:59,353] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:51:59,354] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:51:59,370] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:51:59,375] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,375] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,375] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,375] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,375] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,375] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,376] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,377] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:51:59,390] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:51:59,391] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:51:59,399] INFO Accepted socket connection from /127.0.0.1:49617 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:51:59,401] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:51:59,403] INFO Client attempting to establish new session at /127.0.0.1:49617 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:51:59,415] INFO Established session 0x100178a638b0006 with negotiated timeout 6000 for client /127.0.0.1:49617 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:51:59,416] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100178a638b0006, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:51:59,419] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:51:59,450] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x1 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,470] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x2 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,478] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x3 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,486] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x4 zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,494] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x5 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,501] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x6 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,508] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x7 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,515] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x8 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,522] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0x9 zxid:0xab txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,528] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0xa zxid:0xac txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,536] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0xb zxid:0xad txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,543] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0xc zxid:0xae txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,550] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:create cxid:0xd zxid:0xaf txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:51:59,624] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:51:59,706] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:51:59,709] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:51:59,764] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:51:59,772] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:51:59,794] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:59,794] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:59,795] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:51:59,816] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2019-10-02 21:51:59,824] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:51:59,830] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2019-10-02 21:51:59,846] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:51:59,848] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:52:00,193] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-10-02 21:52:00,199] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:52:00,200] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:52:00,201] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:52:00,222] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:00,226] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-10-02 21:52:00,228] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,228] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,228] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,228] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,228] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,228] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-10-02 21:52:00,228] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,229] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,231] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:00,249] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:00,250] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:00,261] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49619 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:52:00,261] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,263] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,263] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:00,264] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,265] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,266] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49619 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:52:00,274] INFO Established session 0x100178a638b0007 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49619 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:52:00,276] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b0007, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:00,279] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:00,284] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:52:00,317] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x1 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,334] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-10-02 21:52:00,335] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x2 zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,341] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x3 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,349] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x4 zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,358] INFO Stat of the created znode at /brokers/ids/0 is: 180,180,1570067520345,1570067520345,1,0,0,72083477180907526,194,0,180
 (kafka.zk.KafkaZkClient)
[2019-10-02 21:52:00,360] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.7.46,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 180 (kafka.zk.KafkaZkClient)
[2019-10-02 21:52:00,361] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:52:00,361] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x5 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,368] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x6 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,374] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x7 zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,381] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x8 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,388] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0x9 zxid:0xba txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,395] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0xa zxid:0xbb txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,401] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0xb zxid:0xbc txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,408] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0xc zxid:0xbd txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,414] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0007 type:create cxid:0xd zxid:0xbe txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,449] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,452] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,453] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:52:00,475] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:52:00,476] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:52:00,481] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-10-02 21:52:00,498] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:4000,blockEndProducerId:4999) by writing to Zk with path version 5 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:52:00,521] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:52:00,522] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:52:00,522] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:52:00,535] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:52:00,562] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0006 type:multi cxid:0x28 zxid:0xc1 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:00,574] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:52:00,582] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-10-02 21:52:00,588] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:52:00,588] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:52:00,588] INFO Kafka startTimeMs: 1570067520583 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:52:00,589] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:52:00,590] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-10-02 21:52:00,593] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:52:00,656] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:52:00,665] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:52:00,688] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:00,688] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:00,690] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:00,709] INFO Log directory /tmp/kafka-logs-1 not found, creating it. (kafka.log.LogManager)
[2019-10-02 21:52:00,716] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:52:00,724] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[2019-10-02 21:52:00,736] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:52:00,739] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:52:01,004] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to 0.0.0.0:9092: Address already in use.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:605)
	at kafka.network.Acceptor.<init>(SocketServer.scala:481)
	at kafka.network.SocketServer.createAcceptor(SocketServer.scala:253)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:222)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:455)
	at java.base/sun.nio.ch.Net.bind(Net.java:447)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:219)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:601)
	... 13 more
[2019-10-02 21:52:01,006] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:52:01,007] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:52:01,009] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:52:01,012] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:52:01,044] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:52:01,045] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,045] INFO Processed session termination for sessionid: 0x100178a638b0007 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,052] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49619 which had sessionid 0x100178a638b0007 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:52:01,052] INFO Session: 0x100178a638b0007 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,054] INFO EventThread shut down for session: 0x100178a638b0007 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:01,055] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,055] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,072] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:52:01,072] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:52:01,073] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:52:01,088] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,092] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,092] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,093] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,093] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,093] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,093] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,094] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,095] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,107] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,109] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:01,119] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49622 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:52:01,120] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:01,123] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49622 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:52:01,130] INFO Established session 0x100178a638b0008 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49622 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:52:01,131] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b0008, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:01,134] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,160] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x1 zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,175] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x2 zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,182] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x3 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,189] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x4 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,197] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x5 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,204] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x6 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,211] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x7 zxid:0xca txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,218] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x8 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,227] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0x9 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,234] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0xa zxid:0xcd txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,241] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0xb zxid:0xce txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,249] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0xc zxid:0xcf txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,256] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0008 type:create cxid:0xd zxid:0xd0 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,377] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:52:01,379] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:52:01,419] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:52:01,426] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:52:01,443] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,443] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,444] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,458] INFO Log directory /tmp/kafka-logs-2 not found, creating it. (kafka.log.LogManager)
[2019-10-02 21:52:01,464] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:52:01,471] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2019-10-02 21:52:01,481] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:52:01,484] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:52:01,694] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,694] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,694] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:01,747] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Socket server failed to bind to 0.0.0.0:9092: Address already in use.
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:605)
	at kafka.network.Acceptor.<init>(SocketServer.scala:481)
	at kafka.network.SocketServer.createAcceptor(SocketServer.scala:253)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1(SocketServer.scala:222)
	at kafka.network.SocketServer.$anonfun$createDataPlaneAcceptorsAndProcessors$1$adapted(SocketServer.scala:220)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.network.SocketServer.createDataPlaneAcceptorsAndProcessors(SocketServer.scala:220)
	at kafka.network.SocketServer.startup(SocketServer.scala:120)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:255)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
Caused by: java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:455)
	at java.base/sun.nio.ch.Net.bind(Net.java:447)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:219)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at kafka.network.Acceptor.openServerSocket(SocketServer.scala:601)
	... 13 more
[2019-10-02 21:52:01,748] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:52:01,749] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:52:01,751] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:52:01,754] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:52:01,781] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:52:01,781] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,782] INFO Processed session termination for sessionid: 0x100178a638b0008 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:52:01,789] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49622 which had sessionid 0x100178a638b0008 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:52:01,789] INFO Session: 0x100178a638b0008 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:52:01,790] INFO EventThread shut down for session: 0x100178a638b0008 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:52:01,791] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:52:01,791] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:02,446] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:02,446] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:02,446] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:02,699] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:02,699] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:02,699] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:03,450] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:03,450] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:03,450] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:03,703] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:03,703] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:03,704] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:52:03,736] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:52:03,741] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:52:03,742] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-10-02 21:52:03,744] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:52:04,451] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:04,451] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:52:04,452] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:52:04,487] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:52:04,492] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:52:04,493] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-10-02 21:52:04,494] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:54:17,368] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:17,369] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:54:17,370] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-10-02 21:54:17,389] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-10-02 21:54:17,394] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:17,395] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:17,395] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:17,396] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:17,405] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:17,406] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:17,408] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:17,412] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-10-02 21:54:17,412] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:17,609] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:17,609] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:17,611] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:17,612] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 4000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:17,613] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-10-02 21:54:17,613] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:17,613] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:17,613] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:17,614] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:17,614] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:17,615] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:17,811] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:17,811] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:17,812] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,015] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,015] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,016] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:18,017] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-10-02 21:54:18,017] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:18,017] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:18,017] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:18,018] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:18,019] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:18,021] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:18,021] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:18,021] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,217] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,217] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,218] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,422] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,422] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,422] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,624] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,624] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,624] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,822] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,822] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:18,826] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-10-02 21:54:18,826] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:54:18,860] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:54:18,866] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:18,867] INFO Processed session termination for sessionid: 0x100178a638b0006 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:18,875] INFO Closed socket connection for client /127.0.0.1:49617 which had sessionid 0x100178a638b0006 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:54:18,875] INFO Session: 0x100178a638b0006 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:18,876] INFO EventThread shut down for session: 0x100178a638b0006 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:18,877] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:18,877] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:19,204] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:19,204] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:19,205] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:20,208] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:20,208] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:20,209] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:21,212] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:21,212] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:21,214] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:54:21,237] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:54:21,239] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:54:24,168] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:54:24,795] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:24,796] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:54:24,796] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:54:24,813] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:24,818] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,818] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,818] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,818] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,818] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,818] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,819] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,820] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:24,835] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:24,836] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:24,845] INFO Accepted socket connection from /127.0.0.1:49629 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:54:24,847] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:24,849] INFO Client attempting to establish new session at /127.0.0.1:49629 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:54:24,861] INFO Established session 0x100178a638b0009 with negotiated timeout 6000 for client /127.0.0.1:49629 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:54:24,862] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100178a638b0009, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:24,864] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:24,891] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x1 zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,904] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x2 zxid:0xd5 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,911] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x3 zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,919] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x4 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,927] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x5 zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,934] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x6 zxid:0xd9 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,941] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x7 zxid:0xda txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,947] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x8 zxid:0xdb txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,954] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0x9 zxid:0xdc txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,961] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0xa zxid:0xdd txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,968] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0xb zxid:0xde txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,975] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0xc zxid:0xdf txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:24,982] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:create cxid:0xd zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,096] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:54:25,153] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:54:25,212] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:54:25,222] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:54:25,244] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:25,245] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:25,246] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:25,273] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:54:25,280] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[2019-10-02 21:54:25,297] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:54:25,300] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:54:25,628] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-10-02 21:54:25,659] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-10-02 21:54:25,660] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-10-02 21:54:25,675] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:25,675] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:54:25,676] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:54:25,685] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,686] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,687] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,688] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,694] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:25,698] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,698] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,698] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,699] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,699] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,699] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,700] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,702] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:25,702] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:25,717] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:25,718] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:25,729] INFO Accepted socket connection from /127.0.0.1:49631 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:54:25,730] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:25,733] INFO Client attempting to establish new session at /127.0.0.1:49631 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:54:25,740] INFO Established session 0x100178a638b000a with negotiated timeout 6000 for client /127.0.0.1:49631 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:54:25,741] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100178a638b000a, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:25,744] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:25,745] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:25,763] INFO Stat of the created znode at /brokers/ids/0 is: 226,226,1570067665753,1570067665753,1,0,0,72083477180907529,194,0,226
 (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:25,765] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.7.46,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 226 (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:25,777] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x1 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,792] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x2 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,800] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x3 zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,806] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x4 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,815] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x5 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,822] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x6 zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,826] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,828] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x7 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,830] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,831] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:25,835] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x8 zxid:0xea txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,841] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0x9 zxid:0xeb txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,848] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0xa zxid:0xec txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,855] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0xb zxid:0xee txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,856] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:25,861] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:25,864] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-10-02 21:54:25,866] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0xc zxid:0xef txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,873] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:create cxid:0xd zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,891] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:5000,blockEndProducerId:5999) by writing to Zk with path version 6 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:25,915] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:25,917] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:25,918] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:25,958] INFO Got user-level KeeperException when processing sessionid:0x100178a638b0009 type:multi cxid:0x28 zxid:0xf2 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:25,966] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:25,975] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-10-02 21:54:25,980] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:25,980] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:25,980] INFO Kafka startTimeMs: 1570067665976 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:25,982] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-10-02 21:54:26,002] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-10-02 21:54:26,048] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:54:26,051] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:54:26,105] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:54:26,114] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:54:26,133] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:26,133] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:26,135] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:26,158] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:54:26,164] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2019-10-02 21:54:26,176] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:54:26,179] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:54:26,448] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2019-10-02 21:54:26,470] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-10-02 21:54:26,471] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-10-02 21:54:26,491] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,492] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,493] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,494] INFO [ExpirationReaper-1-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,506] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:26,521] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:26,521] INFO starting (kafka.server.KafkaServer)
[2019-10-02 21:54:26,522] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-10-02 21:54:26,539] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:26,544] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,544] INFO Client environment:host.name=192.168.7.46 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,544] INFO Client environment:java.version=12.0.2 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,544] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,544] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk-12.0.2.jdk/Contents/Home (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,544] INFO Client environment:java.class.path=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/activation-1.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/aopalliance-repackaged-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/argparse4j-0.7.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/audience-annotations-0.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/commons-lang3-3.8.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-basic-auth-extension-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-file-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-json-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-runtime-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/connect-transforms-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/guava-20.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-api-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-locator-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/hk2-utils-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-core-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-databind-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-dataformat-csv-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-datatype-jdk8-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-base-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-jaxrs-json-provider-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-jaxb-annotations-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-paranamer-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jackson-module-scala_2.12-2.9.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.annotation-api-1.3.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.inject-2.5.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javassist-3.22.0-CR2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.servlet-api-3.1.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jaxb-api-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-client-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-common-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-container-servlet-core-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-hk2-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-media-jaxb-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jersey-server-2.28.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-client-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-continuation-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-http-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-io-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-security-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-server-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlet-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-servlets-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jetty-util-9.4.18.v20190429.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jopt-simple-5.0.4.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/jsr305-3.0.2.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-clients-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-log4j-appender-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-examples-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-scala_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-streams-test-utils-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka-tools-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0-sources.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/kafka_2.12-2.3.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/log4j-1.2.17.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/lz4-java-1.6.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/maven-artifact-3.6.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/metrics-core-2.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/paranamer-2.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/plexus-utils-3.2.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/reflections-0.9.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/rocksdbjni-5.18.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-library-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/scala-reflect-2.12.8.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-api-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/slf4j-log4j12-1.7.26.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/snappy-java-1.1.7.3.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/spotbugs-annotations-3.1.9.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/validation-api-2.0.1.Final.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zkclient-0.11.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zookeeper-3.4.14.jar:/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts/../kafka-2.3.0/bin/../libs/zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:java.library.path=/Users/benxinniu/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:java.io.tmpdir=/var/folders/kl/m3yf6vwx16bbpgr7j3p9vsdh0000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:os.version=10.14.6 (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:user.name=benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:user.home=/Users/benxinniu (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,545] INFO Client environment:user.dir=/Users/benxinniu/batcave/capstone/vape-kafka-platform/scripts (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,546] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b4c50bc (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:26,551] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:26,559] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:26,561] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:26,568] INFO Stat of the created znode at /brokers/ids/1 is: 243,243,1570067666557,1570067666557,1,0,0,72083477180907530,194,0,243
 (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:26,568] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(192.168.7.46,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 243 (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:26,570] WARN No meta.properties file under dir /tmp/kafka-logs-1/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:54:26,575] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:49634 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-10-02 21:54:26,576] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:26,579] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:49634 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:54:26,585] INFO Established session 0x100178a638b000b with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:49634 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-10-02 21:54:26,587] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100178a638b000b, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:26,591] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:26,620] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,621] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x1 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,622] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,623] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:26,635] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x2 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,636] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:26,642] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x3 zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,642] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:26,645] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-10-02 21:54:26,648] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x4 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,655] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x5 zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,662] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x6 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,670] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:26,676] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x7 zxid:0xfc txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,684] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x8 zxid:0xfd txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,691] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0x9 zxid:0xfe txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,697] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:26,698] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0xa zxid:0xff txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,699] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:26,699] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:26,705] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0xb zxid:0x100 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,711] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0xc zxid:0x101 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,719] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:create cxid:0xd zxid:0x102 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:26,735] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:26,743] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-10-02 21:54:26,747] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:26,747] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:26,747] INFO Kafka startTimeMs: 1570067666743 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:26,749] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-10-02 21:54:26,851] INFO Cluster ID = 807umc0QQOe7YEAEX1XIPw (kafka.server.KafkaServer)
[2019-10-02 21:54:26,854] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:54:26,894] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:54:26,901] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 48
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 2
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-10-02 21:54:26,918] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:26,918] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:26,919] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:26,938] INFO Loading logs. (kafka.log.LogManager)
[2019-10-02 21:54:26,944] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2019-10-02 21:54:26,956] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-10-02 21:54:26,959] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-10-02 21:54:27,217] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2019-10-02 21:54:27,237] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-10-02 21:54:27,238] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-10-02 21:54:27,255] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,256] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,257] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,257] INFO [ExpirationReaper-2-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,266] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:27,307] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:27,324] INFO Stat of the created znode at /brokers/ids/2 is: 259,259,1570067667312,1570067667312,1,0,0,72083477180907531,194,0,259
 (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:27,324] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArrayBuffer(EndPoint(192.168.7.46,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 259 (kafka.zk.KafkaZkClient)
[2019-10-02 21:54:27,325] WARN No meta.properties file under dir /tmp/kafka-logs-2/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-10-02 21:54:27,369] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,370] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,371] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:27,383] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:27,384] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:27,387] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-10-02 21:54:27,400] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:7000,blockEndProducerId:7999) by writing to Zk with path version 8 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:27,417] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:27,418] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:27,418] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:27,445] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:27,451] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-10-02 21:54:27,456] INFO Kafka version: 2.3.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:27,457] INFO Kafka commitId: fc1aaa116b661c8a (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:27,457] INFO Kafka startTimeMs: 1570067667452 (org.apache.kafka.common.utils.AppInfoParser)
[2019-10-02 21:54:27,458] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2019-10-02 21:54:41,270] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:41,271] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:54:41,273] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-10-02 21:54:41,289] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-10-02 21:54:41,294] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:41,295] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:41,295] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:41,296] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:41,305] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:41,306] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:41,307] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:41,311] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2019-10-02 21:54:41,312] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,489] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,490] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,492] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:41,493] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 5000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:41,493] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-10-02 21:54:41,494] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:41,496] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:41,496] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:41,496] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:41,497] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:41,497] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,699] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,699] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,699] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,893] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,893] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,894] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:41,895] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-10-02 21:54:41,896] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:41,896] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:41,896] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:41,897] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:41,898] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:41,898] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:41,899] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:41,899] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,925] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,925] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,925] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,938] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,938] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:41,938] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:42,133] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:42,133] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:42,133] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:42,337] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:42,337] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:42,341] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-10-02 21:54:42,342] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:54:42,377] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:54:42,385] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:42,386] INFO Processed session termination for sessionid: 0x100178a638b0009 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:42,395] INFO Session: 0x100178a638b0009 closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:42,396] INFO Closed socket connection for client /127.0.0.1:49629 which had sessionid 0x100178a638b0009 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:54:42,396] INFO EventThread shut down for session: 0x100178a638b0009 (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:42,397] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:42,398] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:42,402] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:multi cxid:0x26 zxid:0x107 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/controller Error:KeeperErrorCode = NodeExists for /controller (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:42,468] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000a type:multi cxid:0x34 zxid:0x108 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:43,233] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:43,234] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:54:43,236] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-10-02 21:54:43,253] INFO [KafkaServer id=1] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-10-02 21:54:43,257] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:43,257] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:43,257] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:43,258] INFO [SocketServer brokerId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:43,267] INFO [SocketServer brokerId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:43,268] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:43,270] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:43,274] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2019-10-02 21:54:43,275] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,309] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:43,309] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:43,309] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:43,478] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,478] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,481] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:43,482] INFO [ProducerId Manager 1]: Shutdown complete: last producerId assigned 6000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:43,483] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-10-02 21:54:43,483] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:43,486] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:43,486] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:43,486] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:43,487] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:43,487] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,491] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,491] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,491] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,691] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,691] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,692] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:43,693] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2019-10-02 21:54:43,693] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:43,693] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:43,693] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:43,694] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:43,695] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:43,695] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:43,696] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:43,696] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,748] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,748] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,748] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,755] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,755] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,755] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,959] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,959] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:43,959] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:44,159] INFO [ExpirationReaper-1-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:44,159] INFO [ExpirationReaper-1-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:44,162] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2019-10-02 21:54:44,163] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:54:44,198] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:54:44,206] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:44,207] INFO Processed session termination for sessionid: 0x100178a638b000a (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:44,220] INFO Closed socket connection for client /127.0.0.1:49631 which had sessionid 0x100178a638b000a (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:54:44,220] INFO Session: 0x100178a638b000a closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:44,221] INFO EventThread shut down for session: 0x100178a638b000a (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:44,222] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:44,222] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:44,287] INFO Got user-level KeeperException when processing sessionid:0x100178a638b000b type:multi cxid:0x3d zxid:0x10b txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:44,312] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:44,312] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:44,312] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:45,179] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:45,179] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:45,180] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:45,243] INFO Terminating process due to signal SIGHUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2019-10-02 21:54:45,245] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2019-10-02 21:54:45,246] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2019-10-02 21:54:45,263] INFO [KafkaServer id=2] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2019-10-02 21:54:45,267] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:45,267] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:45,267] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-10-02 21:54:45,268] INFO [SocketServer brokerId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:45,278] INFO [SocketServer brokerId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2019-10-02 21:54:45,278] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:45,280] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2019-10-02 21:54:45,284] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2019-10-02 21:54:45,285] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,316] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:45,316] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:45,317] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:54:45,339] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:54:45,341] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:54:45,445] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,445] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,448] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:45,449] INFO [ProducerId Manager 2]: Shutdown complete: last producerId assigned 7000 (kafka.coordinator.transaction.ProducerIdManager)
[2019-10-02 21:54:45,449] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2019-10-02 21:54:45,449] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:45,452] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:45,452] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-10-02 21:54:45,452] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-10-02 21:54:45,453] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:45,453] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,648] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,648] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,648] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,852] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,852] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,853] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2019-10-02 21:54:45,853] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2019-10-02 21:54:45,854] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:45,854] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:45,854] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-10-02 21:54:45,855] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:45,856] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-10-02 21:54:45,856] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:45,857] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-10-02 21:54:45,857] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,970] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,970] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:45,970] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,174] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,174] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,174] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,183] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:46,183] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:46,183] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:46,378] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,378] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,379] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,583] INFO [ExpirationReaper-2-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,583] INFO [ExpirationReaper-2-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-10-02 21:54:46,587] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2019-10-02 21:54:46,587] INFO Shutting down. (kafka.log.LogManager)
[2019-10-02 21:54:46,621] INFO Shutdown complete. (kafka.log.LogManager)
[2019-10-02 21:54:46,627] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:46,628] INFO Processed session termination for sessionid: 0x100178a638b000b (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-10-02 21:54:46,637] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:49634 which had sessionid 0x100178a638b000b (org.apache.zookeeper.server.NIOServerCnxn)
[2019-10-02 21:54:46,637] INFO Session: 0x100178a638b000b closed (org.apache.zookeeper.ZooKeeper)
[2019-10-02 21:54:46,638] INFO EventThread shut down for session: 0x100178a638b000b (org.apache.zookeeper.ClientCnxn)
[2019-10-02 21:54:46,639] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-10-02 21:54:46,639] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:46,982] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:46,983] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:46,982] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,184] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,184] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,185] INFO [SocketServer brokerId=1] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:54:47,215] INFO [SocketServer brokerId=1] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:54:47,217] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2019-10-02 21:54:47,983] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,983] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,984] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,993] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,993] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-10-02 21:54:47,995] INFO [SocketServer brokerId=2] Shutting down socket server (kafka.network.SocketServer)
[2019-10-02 21:54:48,020] INFO [SocketServer brokerId=2] Shutdown completed (kafka.network.SocketServer)
[2019-10-02 21:54:48,021] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
